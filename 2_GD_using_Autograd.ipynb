{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UOajMmdVFGYD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# f = w*x\n",
        "# f = 2*x\n",
        "\n",
        "X = np.array([1,2,3,4],dtype=np.float32)\n",
        "y = np.array([1,4,6,8],dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = 0.0"
      ],
      "metadata": {
        "id": "UT3u1c_CFUaL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model prediction\n",
        "def forward(x):\n",
        "    return w*x\n",
        "\n",
        "#loss\n",
        "def loss(y,y_predicted):\n",
        "    return((y_predicted-y)**2).mean()\n",
        "    "
      ],
      "metadata": {
        "id": "pXmKCezQFmYO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gradient\n",
        "#MSE = 1/N*(w*x-y)**2\n",
        "#dj/dw = 1/N 2x(w*x-y)\n",
        "\n",
        "def gradient(x,y,y_predicted):\n",
        "    return np.dot(2*x,y_predicted-y).mean()"
      ],
      "metadata": {
        "id": "4MQpAzuQFvgu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"prediction before Training : f(5)={forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L626GIQbFy9n",
        "outputId": "7351566b-1575-4d35-93e8-8da96a04896c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before Training : f(5)=0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 30"
      ],
      "metadata": {
        "id": "6peSZnQ-F1Ms"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "for epoch in range(n_iters):\n",
        "    #forward\n",
        "    y_pred = forward(X)\n",
        "    #Loss\n",
        "    l = loss(y,y_pred)\n",
        "    #gradient\n",
        "    dw = gradient(X,y,y_pred)\n",
        "    print(dw)\n",
        "    # update weights\n",
        "    w -= learning_rate*dw\n",
        "    if epoch%1 == 0:\n",
        "        print(f'epoch {epoch+1}: w ={w:.3f},loss={l:.8f}')\n",
        "print(f\"prediction after training:f(5)={forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtM6AX8hF7ft",
        "outputId": "f692c5fe-09f5-46be-de1a-f4431c6771c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-118.0\n",
            "epoch 1: w =1.180,loss=29.25000000\n",
            "-47.2\n",
            "epoch 2: w =1.652,loss=4.88300037\n",
            "-18.880003\n",
            "epoch 3: w =1.841,loss=0.98428023\n",
            "-7.5519986\n",
            "epoch 4: w =1.916,loss=0.36048478\n",
            "-3.0208013\n",
            "epoch 5: w =1.947,loss=0.26067758\n",
            "-1.2083147\n",
            "epoch 6: w =1.959,loss=0.24470837\n",
            "-0.48333144\n",
            "epoch 7: w =1.963,loss=0.24215335\n",
            "-0.19333315\n",
            "epoch 8: w =1.965,loss=0.24174455\n",
            "-0.07733154\n",
            "epoch 9: w =1.966,loss=0.24167913\n",
            "-0.030933619\n",
            "epoch 10: w =1.966,loss=0.24166866\n",
            "-0.012370586\n",
            "epoch 11: w =1.967,loss=0.24166697\n",
            "-0.0049476624\n",
            "epoch 12: w =1.967,loss=0.24166672\n",
            "-0.0019800663\n",
            "epoch 13: w =1.967,loss=0.24166667\n",
            "-0.00079131126\n",
            "epoch 14: w =1.967,loss=0.24166666\n",
            "-0.000320673\n",
            "epoch 15: w =1.967,loss=0.24166666\n",
            "-0.00012540817\n",
            "epoch 16: w =1.967,loss=0.24166666\n",
            "-4.7445297e-05\n",
            "epoch 17: w =1.967,loss=0.24166666\n",
            "-1.8835068e-05\n",
            "epoch 18: w =1.967,loss=0.24166666\n",
            "-1.0967255e-05\n",
            "epoch 19: w =1.967,loss=0.24166664\n",
            "-5.9604645e-06\n",
            "epoch 20: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 21: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 22: w =1.967,loss=0.24166666\n",
            "-5.9604645e-06\n",
            "epoch 23: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 24: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 25: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 26: w =1.967,loss=0.24166666\n",
            "-5.9604645e-06\n",
            "epoch 27: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 28: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 29: w =1.967,loss=0.24166666\n",
            "1.9073486e-06\n",
            "epoch 30: w =1.967,loss=0.24166666\n",
            "prediction after training:f(5)=9.833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second way\n",
        "import torch\n",
        "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "y = torch.tensor([1,4,6,8],dtype=torch.float32)\n",
        "w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)"
      ],
      "metadata": {
        "id": "GaglS5XmF-q2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return w*x\n",
        "def loss(y,y_predicted):\n",
        "    return((y_predicted-y)**2).mean()\n",
        "print(f\"prediction before Training : f(5)={forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37uC2XXOGD3s",
        "outputId": "9b51b798-f2d7-4b08-b36d-c05bf19a7990"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before Training : f(5)=0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_iters = 156"
      ],
      "metadata": {
        "id": "Sj4Ka9Y_GGWF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "    y_pred = forward(X)\n",
        "    l = loss(y,y_pred)\n",
        "    # backword\n",
        "    l.backward()\n",
        "    #update weights\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate*w.grad\n",
        "    #zero grad\n",
        "    w.grad.zero_()\n",
        "    if epoch%1 == 0:\n",
        "        print(f'epoch {epoch+1}: w ={w:.3f},loss={l:.8f}')\n",
        "print(f\"prediction after training:f(5)={forward(5):.3f}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXDOnqDfGI7A",
        "outputId": "0eef484a-cf25-41b1-e884-8b46d0641074"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w =0.295,loss=29.25000000\n",
            "epoch 2: w =0.546,loss=21.20018768\n",
            "epoch 3: w =0.759,loss=15.38419724\n",
            "epoch 4: w =0.940,loss=11.18214512\n",
            "epoch 5: w =1.094,loss=8.14616203\n",
            "epoch 6: w =1.225,loss=5.95266438\n",
            "epoch 7: w =1.336,loss=4.36786270\n",
            "epoch 8: w =1.431,loss=3.22284269\n",
            "epoch 9: w =1.511,loss=2.39556646\n",
            "epoch 10: w =1.579,loss=1.79785860\n",
            "epoch 11: w =1.638,loss=1.36601555\n",
            "epoch 12: w =1.687,loss=1.05400896\n",
            "epoch 13: w =1.729,loss=0.82858384\n",
            "epoch 14: w =1.765,loss=0.66571426\n",
            "epoch 15: w =1.795,loss=0.54804134\n",
            "epoch 16: w =1.821,loss=0.46302229\n",
            "epoch 17: w =1.843,loss=0.40159622\n",
            "epoch 18: w =1.861,loss=0.35721567\n",
            "epoch 19: w =1.877,loss=0.32515085\n",
            "epoch 20: w =1.890,loss=0.30198389\n",
            "epoch 21: w =1.902,loss=0.28524587\n",
            "epoch 22: w =1.912,loss=0.27315259\n",
            "epoch 23: w =1.920,loss=0.26441529\n",
            "epoch 24: w =1.927,loss=0.25810257\n",
            "epoch 25: w =1.933,loss=0.25354165\n",
            "epoch 26: w =1.938,loss=0.25024632\n",
            "epoch 27: w =1.942,loss=0.24786550\n",
            "epoch 28: w =1.946,loss=0.24614532\n",
            "epoch 29: w =1.949,loss=0.24490248\n",
            "epoch 30: w =1.952,loss=0.24400455\n",
            "epoch 31: w =1.954,loss=0.24335578\n",
            "epoch 32: w =1.956,loss=0.24288708\n",
            "epoch 33: w =1.957,loss=0.24254841\n",
            "epoch 34: w =1.959,loss=0.24230374\n",
            "epoch 35: w =1.960,loss=0.24212694\n",
            "epoch 36: w =1.961,loss=0.24199921\n",
            "epoch 37: w =1.962,loss=0.24190693\n",
            "epoch 38: w =1.963,loss=0.24184027\n",
            "epoch 39: w =1.963,loss=0.24179210\n",
            "epoch 40: w =1.964,loss=0.24175730\n",
            "epoch 41: w =1.964,loss=0.24173214\n",
            "epoch 42: w =1.965,loss=0.24171396\n",
            "epoch 43: w =1.965,loss=0.24170083\n",
            "epoch 44: w =1.965,loss=0.24169137\n",
            "epoch 45: w =1.965,loss=0.24168451\n",
            "epoch 46: w =1.966,loss=0.24167953\n",
            "epoch 47: w =1.966,loss=0.24167597\n",
            "epoch 48: w =1.966,loss=0.24167341\n",
            "epoch 49: w =1.966,loss=0.24167153\n",
            "epoch 50: w =1.966,loss=0.24167019\n",
            "epoch 51: w =1.966,loss=0.24166919\n",
            "epoch 52: w =1.966,loss=0.24166849\n",
            "epoch 53: w =1.966,loss=0.24166799\n",
            "epoch 54: w =1.966,loss=0.24166763\n",
            "epoch 55: w =1.966,loss=0.24166735\n",
            "epoch 56: w =1.966,loss=0.24166717\n",
            "epoch 57: w =1.966,loss=0.24166702\n",
            "epoch 58: w =1.967,loss=0.24166693\n",
            "epoch 59: w =1.967,loss=0.24166687\n",
            "epoch 60: w =1.967,loss=0.24166679\n",
            "epoch 61: w =1.967,loss=0.24166678\n",
            "epoch 62: w =1.967,loss=0.24166675\n",
            "epoch 63: w =1.967,loss=0.24166672\n",
            "epoch 64: w =1.967,loss=0.24166670\n",
            "epoch 65: w =1.967,loss=0.24166670\n",
            "epoch 66: w =1.967,loss=0.24166667\n",
            "epoch 67: w =1.967,loss=0.24166667\n",
            "epoch 68: w =1.967,loss=0.24166669\n",
            "epoch 69: w =1.967,loss=0.24166666\n",
            "epoch 70: w =1.967,loss=0.24166667\n",
            "epoch 71: w =1.967,loss=0.24166670\n",
            "epoch 72: w =1.967,loss=0.24166666\n",
            "epoch 73: w =1.967,loss=0.24166667\n",
            "epoch 74: w =1.967,loss=0.24166669\n",
            "epoch 75: w =1.967,loss=0.24166666\n",
            "epoch 76: w =1.967,loss=0.24166667\n",
            "epoch 77: w =1.967,loss=0.24166667\n",
            "epoch 78: w =1.967,loss=0.24166666\n",
            "epoch 79: w =1.967,loss=0.24166666\n",
            "epoch 80: w =1.967,loss=0.24166666\n",
            "epoch 81: w =1.967,loss=0.24166667\n",
            "epoch 82: w =1.967,loss=0.24166666\n",
            "epoch 83: w =1.967,loss=0.24166666\n",
            "epoch 84: w =1.967,loss=0.24166667\n",
            "epoch 85: w =1.967,loss=0.24166666\n",
            "epoch 86: w =1.967,loss=0.24166666\n",
            "epoch 87: w =1.967,loss=0.24166667\n",
            "epoch 88: w =1.967,loss=0.24166667\n",
            "epoch 89: w =1.967,loss=0.24166666\n",
            "epoch 90: w =1.967,loss=0.24166667\n",
            "epoch 91: w =1.967,loss=0.24166666\n",
            "epoch 92: w =1.967,loss=0.24166666\n",
            "epoch 93: w =1.967,loss=0.24166667\n",
            "epoch 94: w =1.967,loss=0.24166667\n",
            "epoch 95: w =1.967,loss=0.24166667\n",
            "epoch 96: w =1.967,loss=0.24166666\n",
            "epoch 97: w =1.967,loss=0.24166666\n",
            "epoch 98: w =1.967,loss=0.24166666\n",
            "epoch 99: w =1.967,loss=0.24166666\n",
            "epoch 100: w =1.967,loss=0.24166666\n",
            "epoch 101: w =1.967,loss=0.24166666\n",
            "epoch 102: w =1.967,loss=0.24166666\n",
            "epoch 103: w =1.967,loss=0.24166666\n",
            "epoch 104: w =1.967,loss=0.24166666\n",
            "epoch 105: w =1.967,loss=0.24166666\n",
            "epoch 106: w =1.967,loss=0.24166666\n",
            "epoch 107: w =1.967,loss=0.24166666\n",
            "epoch 108: w =1.967,loss=0.24166666\n",
            "epoch 109: w =1.967,loss=0.24166666\n",
            "epoch 110: w =1.967,loss=0.24166666\n",
            "epoch 111: w =1.967,loss=0.24166666\n",
            "epoch 112: w =1.967,loss=0.24166666\n",
            "epoch 113: w =1.967,loss=0.24166666\n",
            "epoch 114: w =1.967,loss=0.24166666\n",
            "epoch 115: w =1.967,loss=0.24166666\n",
            "epoch 116: w =1.967,loss=0.24166666\n",
            "epoch 117: w =1.967,loss=0.24166666\n",
            "epoch 118: w =1.967,loss=0.24166666\n",
            "epoch 119: w =1.967,loss=0.24166666\n",
            "epoch 120: w =1.967,loss=0.24166666\n",
            "epoch 121: w =1.967,loss=0.24166666\n",
            "epoch 122: w =1.967,loss=0.24166666\n",
            "epoch 123: w =1.967,loss=0.24166666\n",
            "epoch 124: w =1.967,loss=0.24166666\n",
            "epoch 125: w =1.967,loss=0.24166666\n",
            "epoch 126: w =1.967,loss=0.24166666\n",
            "epoch 127: w =1.967,loss=0.24166666\n",
            "epoch 128: w =1.967,loss=0.24166666\n",
            "epoch 129: w =1.967,loss=0.24166666\n",
            "epoch 130: w =1.967,loss=0.24166666\n",
            "epoch 131: w =1.967,loss=0.24166666\n",
            "epoch 132: w =1.967,loss=0.24166666\n",
            "epoch 133: w =1.967,loss=0.24166666\n",
            "epoch 134: w =1.967,loss=0.24166666\n",
            "epoch 135: w =1.967,loss=0.24166666\n",
            "epoch 136: w =1.967,loss=0.24166666\n",
            "epoch 137: w =1.967,loss=0.24166666\n",
            "epoch 138: w =1.967,loss=0.24166666\n",
            "epoch 139: w =1.967,loss=0.24166666\n",
            "epoch 140: w =1.967,loss=0.24166666\n",
            "epoch 141: w =1.967,loss=0.24166666\n",
            "epoch 142: w =1.967,loss=0.24166666\n",
            "epoch 143: w =1.967,loss=0.24166666\n",
            "epoch 144: w =1.967,loss=0.24166666\n",
            "epoch 145: w =1.967,loss=0.24166666\n",
            "epoch 146: w =1.967,loss=0.24166666\n",
            "epoch 147: w =1.967,loss=0.24166666\n",
            "epoch 148: w =1.967,loss=0.24166666\n",
            "epoch 149: w =1.967,loss=0.24166666\n",
            "epoch 150: w =1.967,loss=0.24166666\n",
            "epoch 151: w =1.967,loss=0.24166666\n",
            "epoch 152: w =1.967,loss=0.24166666\n",
            "epoch 153: w =1.967,loss=0.24166666\n",
            "epoch 154: w =1.967,loss=0.24166666\n",
            "epoch 155: w =1.967,loss=0.24166666\n",
            "epoch 156: w =1.967,loss=0.24166666\n",
            "prediction after training:f(5)=9.833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3rd way\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "y = torch.tensor([1,4,6,8],dtype=torch.float32)\n",
        "w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)"
      ],
      "metadata": {
        "id": "97VM34ATGK_3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return w*x"
      ],
      "metadata": {
        "id": "_kPYNjJSGd46"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"prediction before Training : f(5)={forward(5):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDUNrh3NGgRC",
        "outputId": "994c0688-ec2f-4bbb-d82e-65f655d3dbc1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before Training : f(5)=0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w],lr=learning_rate)"
      ],
      "metadata": {
        "id": "rD_gU6mSGiaN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "    y_pred = forward(X)\n",
        "    l = loss(y,y_pred)\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if epoch%1 == 0:\n",
        "        print(f'epoch {epoch+1}: w ={w:.3f},loss={l:.8f}')\n",
        "print(f\"prediction after training:f(5)={forward(5):.3f}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTmH7t1lGkef",
        "outputId": "64cc705c-0e47-4256-cfab-b3da6ee03df8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w =0.295,loss=29.25000000\n",
            "epoch 2: w =0.546,loss=21.20018768\n",
            "epoch 3: w =0.759,loss=15.38419914\n",
            "epoch 4: w =0.940,loss=11.18214607\n",
            "epoch 5: w =1.094,loss=8.14616203\n",
            "epoch 6: w =1.225,loss=5.95266438\n",
            "epoch 7: w =1.336,loss=4.36786270\n",
            "epoch 8: w =1.431,loss=3.22284269\n",
            "epoch 9: w =1.511,loss=2.39556646\n",
            "epoch 10: w =1.579,loss=1.79785860\n",
            "epoch 11: w =1.638,loss=1.36601555\n",
            "epoch 12: w =1.687,loss=1.05400896\n",
            "epoch 13: w =1.729,loss=0.82858384\n",
            "epoch 14: w =1.765,loss=0.66571426\n",
            "epoch 15: w =1.795,loss=0.54804134\n",
            "epoch 16: w =1.821,loss=0.46302229\n",
            "epoch 17: w =1.843,loss=0.40159622\n",
            "epoch 18: w =1.861,loss=0.35721567\n",
            "epoch 19: w =1.877,loss=0.32515085\n",
            "epoch 20: w =1.890,loss=0.30198389\n",
            "epoch 21: w =1.902,loss=0.28524587\n",
            "epoch 22: w =1.912,loss=0.27315259\n",
            "epoch 23: w =1.920,loss=0.26441529\n",
            "epoch 24: w =1.927,loss=0.25810257\n",
            "epoch 25: w =1.933,loss=0.25354165\n",
            "epoch 26: w =1.938,loss=0.25024632\n",
            "epoch 27: w =1.942,loss=0.24786550\n",
            "epoch 28: w =1.946,loss=0.24614532\n",
            "epoch 29: w =1.949,loss=0.24490248\n",
            "epoch 30: w =1.952,loss=0.24400455\n",
            "epoch 31: w =1.954,loss=0.24335578\n",
            "epoch 32: w =1.956,loss=0.24288708\n",
            "epoch 33: w =1.957,loss=0.24254841\n",
            "epoch 34: w =1.959,loss=0.24230374\n",
            "epoch 35: w =1.960,loss=0.24212694\n",
            "epoch 36: w =1.961,loss=0.24199921\n",
            "epoch 37: w =1.962,loss=0.24190693\n",
            "epoch 38: w =1.963,loss=0.24184027\n",
            "epoch 39: w =1.963,loss=0.24179210\n",
            "epoch 40: w =1.964,loss=0.24175730\n",
            "epoch 41: w =1.964,loss=0.24173214\n",
            "epoch 42: w =1.965,loss=0.24171396\n",
            "epoch 43: w =1.965,loss=0.24170083\n",
            "epoch 44: w =1.965,loss=0.24169137\n",
            "epoch 45: w =1.965,loss=0.24168451\n",
            "epoch 46: w =1.966,loss=0.24167953\n",
            "epoch 47: w =1.966,loss=0.24167597\n",
            "epoch 48: w =1.966,loss=0.24167341\n",
            "epoch 49: w =1.966,loss=0.24167153\n",
            "epoch 50: w =1.966,loss=0.24167019\n",
            "epoch 51: w =1.966,loss=0.24166919\n",
            "epoch 52: w =1.966,loss=0.24166849\n",
            "epoch 53: w =1.966,loss=0.24166799\n",
            "epoch 54: w =1.966,loss=0.24166763\n",
            "epoch 55: w =1.966,loss=0.24166735\n",
            "epoch 56: w =1.966,loss=0.24166717\n",
            "epoch 57: w =1.966,loss=0.24166702\n",
            "epoch 58: w =1.967,loss=0.24166693\n",
            "epoch 59: w =1.967,loss=0.24166687\n",
            "epoch 60: w =1.967,loss=0.24166679\n",
            "epoch 61: w =1.967,loss=0.24166678\n",
            "epoch 62: w =1.967,loss=0.24166675\n",
            "epoch 63: w =1.967,loss=0.24166672\n",
            "epoch 64: w =1.967,loss=0.24166670\n",
            "epoch 65: w =1.967,loss=0.24166670\n",
            "epoch 66: w =1.967,loss=0.24166667\n",
            "epoch 67: w =1.967,loss=0.24166667\n",
            "epoch 68: w =1.967,loss=0.24166669\n",
            "epoch 69: w =1.967,loss=0.24166666\n",
            "epoch 70: w =1.967,loss=0.24166667\n",
            "epoch 71: w =1.967,loss=0.24166670\n",
            "epoch 72: w =1.967,loss=0.24166666\n",
            "epoch 73: w =1.967,loss=0.24166667\n",
            "epoch 74: w =1.967,loss=0.24166669\n",
            "epoch 75: w =1.967,loss=0.24166666\n",
            "epoch 76: w =1.967,loss=0.24166667\n",
            "epoch 77: w =1.967,loss=0.24166667\n",
            "epoch 78: w =1.967,loss=0.24166666\n",
            "epoch 79: w =1.967,loss=0.24166666\n",
            "epoch 80: w =1.967,loss=0.24166666\n",
            "epoch 81: w =1.967,loss=0.24166667\n",
            "epoch 82: w =1.967,loss=0.24166666\n",
            "epoch 83: w =1.967,loss=0.24166666\n",
            "epoch 84: w =1.967,loss=0.24166667\n",
            "epoch 85: w =1.967,loss=0.24166666\n",
            "epoch 86: w =1.967,loss=0.24166666\n",
            "epoch 87: w =1.967,loss=0.24166667\n",
            "epoch 88: w =1.967,loss=0.24166667\n",
            "epoch 89: w =1.967,loss=0.24166666\n",
            "epoch 90: w =1.967,loss=0.24166667\n",
            "epoch 91: w =1.967,loss=0.24166666\n",
            "epoch 92: w =1.967,loss=0.24166666\n",
            "epoch 93: w =1.967,loss=0.24166667\n",
            "epoch 94: w =1.967,loss=0.24166667\n",
            "epoch 95: w =1.967,loss=0.24166667\n",
            "epoch 96: w =1.967,loss=0.24166666\n",
            "epoch 97: w =1.967,loss=0.24166666\n",
            "epoch 98: w =1.967,loss=0.24166666\n",
            "epoch 99: w =1.967,loss=0.24166666\n",
            "epoch 100: w =1.967,loss=0.24166666\n",
            "prediction after training:f(5)=9.833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4th way\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "y = torch.tensor([[1],[4],[6],[8]],dtype=torch.float32)\n",
        "X_test = torch.tensor([5],dtype=torch.float32)"
      ],
      "metadata": {
        "id": "j1T_l5n2Gm_N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0W5qBk5GuBQ",
        "outputId": "d5386f86-87b0-4f9b-ca20-44edba91ef97"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_features = X.shape\n",
        "print(n_samples)\n",
        "print(n_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8MhpsWOGwHZ",
        "outputId": "28c17247-f486-4bbe-eaee-ce65b1aa895a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = n_features\n",
        "output_size = n_features"
      ],
      "metadata": {
        "id": "ztTDhWSHGyd_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(input_size,output_size)"
      ],
      "metadata": {
        "id": "LiqHLM-FG0fg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"prediction before Training : f(5)={model(X_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DZiPt9-G22j",
        "outputId": "cc51106f-03fe-40ee-9c07-6904b9ede100"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before Training : f(5)=-4.162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "3yKVPV-aG5O6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "    y_pred = model(X)\n",
        "    l = loss(y,y_pred)\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if epoch%1 == 0:\n",
        "        [w,b] = model.parameters()\n",
        "        print(f'epoch {epoch+1}: w ={w[0][0].item():.3f},loss={l:.8f}')\n",
        "print(f\"prediction after training:f(5)={model(X_test).item():.3f}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHIWeUVZG7ZB",
        "outputId": "f9c0d142-7828-40a9-b1d4-dfadf6364452"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w =-0.384,loss=59.68071365\n",
            "epoch 2: w =-0.032,loss=41.58399582\n",
            "epoch 3: w =0.261,loss=29.02616882\n",
            "epoch 4: w =0.506,loss=20.31166840\n",
            "epoch 5: w =0.710,loss=14.26397514\n",
            "epoch 6: w =0.881,loss=10.06672859\n",
            "epoch 7: w =1.023,loss=7.15347433\n",
            "epoch 8: w =1.142,loss=5.13115978\n",
            "epoch 9: w =1.241,loss=3.72705364\n",
            "epoch 10: w =1.324,loss=2.75191498\n",
            "epoch 11: w =1.394,loss=2.07443285\n",
            "epoch 12: w =1.452,loss=1.60349309\n",
            "epoch 13: w =1.500,loss=1.27587485\n",
            "epoch 14: w =1.541,loss=1.04770827\n",
            "epoch 15: w =1.575,loss=0.88855469\n",
            "epoch 16: w =1.604,loss=0.77729291\n",
            "epoch 17: w =1.628,loss=0.69926679\n",
            "epoch 18: w =1.649,loss=0.64430726\n",
            "epoch 19: w =1.666,loss=0.60535777\n",
            "epoch 20: w =1.681,loss=0.57752270\n",
            "epoch 21: w =1.694,loss=0.55740404\n",
            "epoch 22: w =1.704,loss=0.54264480\n",
            "epoch 23: w =1.713,loss=0.53160918\n",
            "epoch 24: w =1.721,loss=0.52316159\n",
            "epoch 25: w =1.728,loss=0.51651496\n",
            "epoch 26: w =1.734,loss=0.51112223\n",
            "epoch 27: w =1.740,loss=0.50660479\n",
            "epoch 28: w =1.744,loss=0.50269890\n",
            "epoch 29: w =1.748,loss=0.49922210\n",
            "epoch 30: w =1.752,loss=0.49604774\n",
            "epoch 31: w =1.755,loss=0.49308747\n",
            "epoch 32: w =1.758,loss=0.49028060\n",
            "epoch 33: w =1.761,loss=0.48758447\n",
            "epoch 34: w =1.764,loss=0.48496976\n",
            "epoch 35: w =1.766,loss=0.48241597\n",
            "epoch 36: w =1.769,loss=0.47990879\n",
            "epoch 37: w =1.771,loss=0.47743863\n",
            "epoch 38: w =1.773,loss=0.47499812\n",
            "epoch 39: w =1.775,loss=0.47258291\n",
            "epoch 40: w =1.777,loss=0.47018927\n",
            "epoch 41: w =1.779,loss=0.46781504\n",
            "epoch 42: w =1.780,loss=0.46545848\n",
            "epoch 43: w =1.782,loss=0.46311846\n",
            "epoch 44: w =1.784,loss=0.46079412\n",
            "epoch 45: w =1.785,loss=0.45848492\n",
            "epoch 46: w =1.787,loss=0.45619026\n",
            "epoch 47: w =1.789,loss=0.45390993\n",
            "epoch 48: w =1.790,loss=0.45164353\n",
            "epoch 49: w =1.792,loss=0.44939107\n",
            "epoch 50: w =1.794,loss=0.44715232\n",
            "epoch 51: w =1.795,loss=0.44492698\n",
            "epoch 52: w =1.797,loss=0.44271499\n",
            "epoch 53: w =1.798,loss=0.44051641\n",
            "epoch 54: w =1.800,loss=0.43833086\n",
            "epoch 55: w =1.801,loss=0.43615842\n",
            "epoch 56: w =1.803,loss=0.43399927\n",
            "epoch 57: w =1.804,loss=0.43185270\n",
            "epoch 58: w =1.806,loss=0.42971906\n",
            "epoch 59: w =1.807,loss=0.42759821\n",
            "epoch 60: w =1.809,loss=0.42549014\n",
            "epoch 61: w =1.810,loss=0.42339450\n",
            "epoch 62: w =1.812,loss=0.42131153\n",
            "epoch 63: w =1.813,loss=0.41924107\n",
            "epoch 64: w =1.815,loss=0.41718295\n",
            "epoch 65: w =1.816,loss=0.41513711\n",
            "epoch 66: w =1.818,loss=0.41310346\n",
            "epoch 67: w =1.819,loss=0.41108191\n",
            "epoch 68: w =1.820,loss=0.40907267\n",
            "epoch 69: w =1.822,loss=0.40707517\n",
            "epoch 70: w =1.823,loss=0.40508974\n",
            "epoch 71: w =1.825,loss=0.40311623\n",
            "epoch 72: w =1.826,loss=0.40115455\n",
            "epoch 73: w =1.828,loss=0.39920449\n",
            "epoch 74: w =1.829,loss=0.39726603\n",
            "epoch 75: w =1.830,loss=0.39533931\n",
            "epoch 76: w =1.832,loss=0.39342400\n",
            "epoch 77: w =1.833,loss=0.39152026\n",
            "epoch 78: w =1.835,loss=0.38962781\n",
            "epoch 79: w =1.836,loss=0.38774669\n",
            "epoch 80: w =1.837,loss=0.38587686\n",
            "epoch 81: w =1.839,loss=0.38401821\n",
            "epoch 82: w =1.840,loss=0.38217074\n",
            "epoch 83: w =1.841,loss=0.38033408\n",
            "epoch 84: w =1.843,loss=0.37850866\n",
            "epoch 85: w =1.844,loss=0.37669399\n",
            "epoch 86: w =1.846,loss=0.37489003\n",
            "epoch 87: w =1.847,loss=0.37309718\n",
            "epoch 88: w =1.848,loss=0.37131485\n",
            "epoch 89: w =1.850,loss=0.36954325\n",
            "epoch 90: w =1.851,loss=0.36778209\n",
            "epoch 91: w =1.852,loss=0.36603168\n",
            "epoch 92: w =1.854,loss=0.36429173\n",
            "epoch 93: w =1.855,loss=0.36256200\n",
            "epoch 94: w =1.856,loss=0.36084270\n",
            "epoch 95: w =1.858,loss=0.35913378\n",
            "epoch 96: w =1.859,loss=0.35743490\n",
            "epoch 97: w =1.860,loss=0.35574630\n",
            "epoch 98: w =1.862,loss=0.35406786\n",
            "epoch 99: w =1.863,loss=0.35239941\n",
            "epoch 100: w =1.864,loss=0.35074073\n",
            "prediction after training:f(5)=9.602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating model class"
      ],
      "metadata": {
        "id": "jb8_OOb4G9vw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "y = torch.tensor([[1],[4],[6],[8]],dtype=torch.float32)\n",
        "X_test = torch.tensor([5],dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples)\n",
        "print(n_features)\n",
        "\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMWBRlmLHBwy",
        "outputId": "031ff08f-27ef-4510-c70b-590e7a2b118b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self,input_dim,output_dim):\n",
        "        super(LinearRegression,self).__init__()\n",
        "        self.lin = nn.Linear(input_dim,output_dim)\n",
        "    def forward(self,x):\n",
        "        return self.lin(x)"
      ],
      "metadata": {
        "id": "ex8pZ0crHD-z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression(input_size,output_size)"
      ],
      "metadata": {
        "id": "69OhILWZHGY4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"prediction before Training : f(5)={model(X_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz0AaD5lHItv",
        "outputId": "ff55118b-145b-4405-c82a-f7cd8deb87e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before Training : f(5)=0.723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "n_iters = 500\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "HC2OtMHiHLLL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "    y_pred = model.forward(X)\n",
        "    l = loss(y,y_pred)\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if epoch%1 == 0:\n",
        "        [w,b] = model.parameters()\n",
        "        print(f'epoch {epoch+1}: w ={w[0][0].item():.3f},loss={l:.8f}')\n",
        "print(f\"prediction after training:f(5)={model(X_test).item():.3f}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6A6dCRHHNpG",
        "outputId": "e1a8a8e6-6df9-4d37-ff3d-3ccb05f4bfe8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: w =0.599,loss=28.06897736\n",
            "epoch 2: w =0.840,loss=19.52884865\n",
            "epoch 3: w =1.042,loss=13.60285664\n",
            "epoch 4: w =1.209,loss=9.49076366\n",
            "epoch 5: w =1.349,loss=6.63729286\n",
            "epoch 6: w =1.466,loss=4.65715885\n",
            "epoch 7: w =1.563,loss=3.28301382\n",
            "epoch 8: w =1.644,loss=2.32935238\n",
            "epoch 9: w =1.712,loss=1.66745675\n",
            "epoch 10: w =1.769,loss=1.20801449\n",
            "epoch 11: w =1.816,loss=0.88904798\n",
            "epoch 12: w =1.856,loss=0.66755784\n",
            "epoch 13: w =1.889,loss=0.51370478\n",
            "epoch 14: w =1.916,loss=0.40678474\n",
            "epoch 15: w =1.939,loss=0.33243129\n",
            "epoch 16: w =1.959,loss=0.28067628\n",
            "epoch 17: w =1.975,loss=0.24460307\n",
            "epoch 18: w =1.989,loss=0.21941189\n",
            "epoch 19: w =2.000,loss=0.20177236\n",
            "epoch 20: w =2.010,loss=0.18937391\n",
            "epoch 21: w =2.018,loss=0.18061306\n",
            "epoch 22: w =2.025,loss=0.17437702\n",
            "epoch 23: w =2.031,loss=0.16989389\n",
            "epoch 24: w =2.036,loss=0.16662811\n",
            "epoch 25: w =2.040,loss=0.16420794\n",
            "epoch 26: w =2.044,loss=0.16237532\n",
            "epoch 27: w =2.047,loss=0.16095142\n",
            "epoch 28: w =2.050,loss=0.15981197\n",
            "epoch 29: w =2.052,loss=0.15887088\n",
            "epoch 30: w =2.055,loss=0.15806831\n",
            "epoch 31: w =2.057,loss=0.15736265\n",
            "epoch 32: w =2.058,loss=0.15672524\n",
            "epoch 33: w =2.060,loss=0.15613598\n",
            "epoch 34: w =2.061,loss=0.15558109\n",
            "epoch 35: w =2.063,loss=0.15505086\n",
            "epoch 36: w =2.064,loss=0.15453863\n",
            "epoch 37: w =2.065,loss=0.15403971\n",
            "epoch 38: w =2.066,loss=0.15355103\n",
            "epoch 39: w =2.067,loss=0.15307015\n",
            "epoch 40: w =2.068,loss=0.15259553\n",
            "epoch 41: w =2.069,loss=0.15212624\n",
            "epoch 42: w =2.069,loss=0.15166132\n",
            "epoch 43: w =2.070,loss=0.15120041\n",
            "epoch 44: w =2.071,loss=0.15074298\n",
            "epoch 45: w =2.072,loss=0.15028889\n",
            "epoch 46: w =2.073,loss=0.14983787\n",
            "epoch 47: w =2.073,loss=0.14938986\n",
            "epoch 48: w =2.074,loss=0.14894466\n",
            "epoch 49: w =2.075,loss=0.14850225\n",
            "epoch 50: w =2.076,loss=0.14806265\n",
            "epoch 51: w =2.076,loss=0.14762561\n",
            "epoch 52: w =2.077,loss=0.14719135\n",
            "epoch 53: w =2.078,loss=0.14675958\n",
            "epoch 54: w =2.078,loss=0.14633054\n",
            "epoch 55: w =2.079,loss=0.14590402\n",
            "epoch 56: w =2.080,loss=0.14548005\n",
            "epoch 57: w =2.080,loss=0.14505868\n",
            "epoch 58: w =2.081,loss=0.14463976\n",
            "epoch 59: w =2.082,loss=0.14422339\n",
            "epoch 60: w =2.082,loss=0.14380953\n",
            "epoch 61: w =2.083,loss=0.14339814\n",
            "epoch 62: w =2.084,loss=0.14298920\n",
            "epoch 63: w =2.084,loss=0.14258268\n",
            "epoch 64: w =2.085,loss=0.14217860\n",
            "epoch 65: w =2.086,loss=0.14177695\n",
            "epoch 66: w =2.086,loss=0.14137770\n",
            "epoch 67: w =2.087,loss=0.14098085\n",
            "epoch 68: w =2.087,loss=0.14058636\n",
            "epoch 69: w =2.088,loss=0.14019424\n",
            "epoch 70: w =2.089,loss=0.13980442\n",
            "epoch 71: w =2.089,loss=0.13941698\n",
            "epoch 72: w =2.090,loss=0.13903184\n",
            "epoch 73: w =2.091,loss=0.13864899\n",
            "epoch 74: w =2.091,loss=0.13826847\n",
            "epoch 75: w =2.092,loss=0.13789025\n",
            "epoch 76: w =2.093,loss=0.13751416\n",
            "epoch 77: w =2.093,loss=0.13714041\n",
            "epoch 78: w =2.094,loss=0.13676891\n",
            "epoch 79: w =2.094,loss=0.13639958\n",
            "epoch 80: w =2.095,loss=0.13603251\n",
            "epoch 81: w =2.096,loss=0.13566756\n",
            "epoch 82: w =2.096,loss=0.13530487\n",
            "epoch 83: w =2.097,loss=0.13494430\n",
            "epoch 84: w =2.097,loss=0.13458595\n",
            "epoch 85: w =2.098,loss=0.13422966\n",
            "epoch 86: w =2.099,loss=0.13387553\n",
            "epoch 87: w =2.099,loss=0.13352355\n",
            "epoch 88: w =2.100,loss=0.13317364\n",
            "epoch 89: w =2.100,loss=0.13282584\n",
            "epoch 90: w =2.101,loss=0.13248010\n",
            "epoch 91: w =2.102,loss=0.13213642\n",
            "epoch 92: w =2.102,loss=0.13179483\n",
            "epoch 93: w =2.103,loss=0.13145526\n",
            "epoch 94: w =2.103,loss=0.13111773\n",
            "epoch 95: w =2.104,loss=0.13078222\n",
            "epoch 96: w =2.105,loss=0.13044867\n",
            "epoch 97: w =2.105,loss=0.13011718\n",
            "epoch 98: w =2.106,loss=0.12978759\n",
            "epoch 99: w =2.106,loss=0.12946008\n",
            "epoch 100: w =2.107,loss=0.12913443\n",
            "epoch 101: w =2.108,loss=0.12881079\n",
            "epoch 102: w =2.108,loss=0.12848906\n",
            "epoch 103: w =2.109,loss=0.12816927\n",
            "epoch 104: w =2.109,loss=0.12785134\n",
            "epoch 105: w =2.110,loss=0.12753537\n",
            "epoch 106: w =2.110,loss=0.12722130\n",
            "epoch 107: w =2.111,loss=0.12690905\n",
            "epoch 108: w =2.112,loss=0.12659872\n",
            "epoch 109: w =2.112,loss=0.12629019\n",
            "epoch 110: w =2.113,loss=0.12598351\n",
            "epoch 111: w =2.113,loss=0.12567870\n",
            "epoch 112: w =2.114,loss=0.12537573\n",
            "epoch 113: w =2.114,loss=0.12507451\n",
            "epoch 114: w =2.115,loss=0.12477513\n",
            "epoch 115: w =2.115,loss=0.12447756\n",
            "epoch 116: w =2.116,loss=0.12418173\n",
            "epoch 117: w =2.117,loss=0.12388762\n",
            "epoch 118: w =2.117,loss=0.12359534\n",
            "epoch 119: w =2.118,loss=0.12330482\n",
            "epoch 120: w =2.118,loss=0.12301598\n",
            "epoch 121: w =2.119,loss=0.12272892\n",
            "epoch 122: w =2.119,loss=0.12244359\n",
            "epoch 123: w =2.120,loss=0.12215988\n",
            "epoch 124: w =2.120,loss=0.12187796\n",
            "epoch 125: w =2.121,loss=0.12159768\n",
            "epoch 126: w =2.121,loss=0.12131910\n",
            "epoch 127: w =2.122,loss=0.12104214\n",
            "epoch 128: w =2.122,loss=0.12076688\n",
            "epoch 129: w =2.123,loss=0.12049323\n",
            "epoch 130: w =2.124,loss=0.12022123\n",
            "epoch 131: w =2.124,loss=0.11995087\n",
            "epoch 132: w =2.125,loss=0.11968208\n",
            "epoch 133: w =2.125,loss=0.11941494\n",
            "epoch 134: w =2.126,loss=0.11914941\n",
            "epoch 135: w =2.126,loss=0.11888544\n",
            "epoch 136: w =2.127,loss=0.11862306\n",
            "epoch 137: w =2.127,loss=0.11836223\n",
            "epoch 138: w =2.128,loss=0.11810299\n",
            "epoch 139: w =2.128,loss=0.11784532\n",
            "epoch 140: w =2.129,loss=0.11758911\n",
            "epoch 141: w =2.129,loss=0.11733451\n",
            "epoch 142: w =2.130,loss=0.11708134\n",
            "epoch 143: w =2.130,loss=0.11682978\n",
            "epoch 144: w =2.131,loss=0.11657967\n",
            "epoch 145: w =2.131,loss=0.11633106\n",
            "epoch 146: w =2.132,loss=0.11608400\n",
            "epoch 147: w =2.132,loss=0.11583837\n",
            "epoch 148: w =2.133,loss=0.11559418\n",
            "epoch 149: w =2.133,loss=0.11535148\n",
            "epoch 150: w =2.134,loss=0.11511019\n",
            "epoch 151: w =2.134,loss=0.11487038\n",
            "epoch 152: w =2.135,loss=0.11463201\n",
            "epoch 153: w =2.135,loss=0.11439505\n",
            "epoch 154: w =2.136,loss=0.11415953\n",
            "epoch 155: w =2.136,loss=0.11392542\n",
            "epoch 156: w =2.137,loss=0.11369266\n",
            "epoch 157: w =2.137,loss=0.11346132\n",
            "epoch 158: w =2.138,loss=0.11323136\n",
            "epoch 159: w =2.138,loss=0.11300281\n",
            "epoch 160: w =2.139,loss=0.11277559\n",
            "epoch 161: w =2.139,loss=0.11254976\n",
            "epoch 162: w =2.140,loss=0.11232527\n",
            "epoch 163: w =2.140,loss=0.11210214\n",
            "epoch 164: w =2.141,loss=0.11188028\n",
            "epoch 165: w =2.141,loss=0.11165977\n",
            "epoch 166: w =2.142,loss=0.11144060\n",
            "epoch 167: w =2.142,loss=0.11122276\n",
            "epoch 168: w =2.143,loss=0.11100618\n",
            "epoch 169: w =2.143,loss=0.11079089\n",
            "epoch 170: w =2.143,loss=0.11057692\n",
            "epoch 171: w =2.144,loss=0.11036418\n",
            "epoch 172: w =2.144,loss=0.11015274\n",
            "epoch 173: w =2.145,loss=0.10994259\n",
            "epoch 174: w =2.145,loss=0.10973368\n",
            "epoch 175: w =2.146,loss=0.10952599\n",
            "epoch 176: w =2.146,loss=0.10931955\n",
            "epoch 177: w =2.147,loss=0.10911433\n",
            "epoch 178: w =2.147,loss=0.10891043\n",
            "epoch 179: w =2.148,loss=0.10870767\n",
            "epoch 180: w =2.148,loss=0.10850617\n",
            "epoch 181: w =2.149,loss=0.10830579\n",
            "epoch 182: w =2.149,loss=0.10810669\n",
            "epoch 183: w =2.149,loss=0.10790870\n",
            "epoch 184: w =2.150,loss=0.10771196\n",
            "epoch 185: w =2.150,loss=0.10751639\n",
            "epoch 186: w =2.151,loss=0.10732202\n",
            "epoch 187: w =2.151,loss=0.10712876\n",
            "epoch 188: w =2.152,loss=0.10693668\n",
            "epoch 189: w =2.152,loss=0.10674568\n",
            "epoch 190: w =2.153,loss=0.10655589\n",
            "epoch 191: w =2.153,loss=0.10636722\n",
            "epoch 192: w =2.153,loss=0.10617968\n",
            "epoch 193: w =2.154,loss=0.10599329\n",
            "epoch 194: w =2.154,loss=0.10580796\n",
            "epoch 195: w =2.155,loss=0.10562380\n",
            "epoch 196: w =2.155,loss=0.10544071\n",
            "epoch 197: w =2.156,loss=0.10525867\n",
            "epoch 198: w =2.156,loss=0.10507778\n",
            "epoch 199: w =2.157,loss=0.10489795\n",
            "epoch 200: w =2.157,loss=0.10471921\n",
            "epoch 201: w =2.157,loss=0.10454147\n",
            "epoch 202: w =2.158,loss=0.10436486\n",
            "epoch 203: w =2.158,loss=0.10418934\n",
            "epoch 204: w =2.159,loss=0.10401478\n",
            "epoch 205: w =2.159,loss=0.10384130\n",
            "epoch 206: w =2.160,loss=0.10366891\n",
            "epoch 207: w =2.160,loss=0.10349747\n",
            "epoch 208: w =2.160,loss=0.10332709\n",
            "epoch 209: w =2.161,loss=0.10315770\n",
            "epoch 210: w =2.161,loss=0.10298936\n",
            "epoch 211: w =2.162,loss=0.10282206\n",
            "epoch 212: w =2.162,loss=0.10265565\n",
            "epoch 213: w =2.162,loss=0.10249033\n",
            "epoch 214: w =2.163,loss=0.10232599\n",
            "epoch 215: w =2.163,loss=0.10216257\n",
            "epoch 216: w =2.164,loss=0.10200018\n",
            "epoch 217: w =2.164,loss=0.10183878\n",
            "epoch 218: w =2.164,loss=0.10167837\n",
            "epoch 219: w =2.165,loss=0.10151882\n",
            "epoch 220: w =2.165,loss=0.10136025\n",
            "epoch 221: w =2.166,loss=0.10120263\n",
            "epoch 222: w =2.166,loss=0.10104595\n",
            "epoch 223: w =2.166,loss=0.10089027\n",
            "epoch 224: w =2.167,loss=0.10073548\n",
            "epoch 225: w =2.167,loss=0.10058162\n",
            "epoch 226: w =2.168,loss=0.10042863\n",
            "epoch 227: w =2.168,loss=0.10027657\n",
            "epoch 228: w =2.168,loss=0.10012551\n",
            "epoch 229: w =2.169,loss=0.09997527\n",
            "epoch 230: w =2.169,loss=0.09982595\n",
            "epoch 231: w =2.170,loss=0.09967751\n",
            "epoch 232: w =2.170,loss=0.09952994\n",
            "epoch 233: w =2.170,loss=0.09938326\n",
            "epoch 234: w =2.171,loss=0.09923749\n",
            "epoch 235: w =2.171,loss=0.09909257\n",
            "epoch 236: w =2.172,loss=0.09894854\n",
            "epoch 237: w =2.172,loss=0.09880541\n",
            "epoch 238: w =2.172,loss=0.09866302\n",
            "epoch 239: w =2.173,loss=0.09852159\n",
            "epoch 240: w =2.173,loss=0.09838093\n",
            "epoch 241: w =2.174,loss=0.09824114\n",
            "epoch 242: w =2.174,loss=0.09810215\n",
            "epoch 243: w =2.174,loss=0.09796405\n",
            "epoch 244: w =2.175,loss=0.09782673\n",
            "epoch 245: w =2.175,loss=0.09769025\n",
            "epoch 246: w =2.175,loss=0.09755457\n",
            "epoch 247: w =2.176,loss=0.09741978\n",
            "epoch 248: w =2.176,loss=0.09728565\n",
            "epoch 249: w =2.176,loss=0.09715249\n",
            "epoch 250: w =2.177,loss=0.09702002\n",
            "epoch 251: w =2.177,loss=0.09688834\n",
            "epoch 252: w =2.178,loss=0.09675747\n",
            "epoch 253: w =2.178,loss=0.09662744\n",
            "epoch 254: w =2.178,loss=0.09649810\n",
            "epoch 255: w =2.179,loss=0.09636959\n",
            "epoch 256: w =2.179,loss=0.09624179\n",
            "epoch 257: w =2.179,loss=0.09611484\n",
            "epoch 258: w =2.180,loss=0.09598853\n",
            "epoch 259: w =2.180,loss=0.09586307\n",
            "epoch 260: w =2.181,loss=0.09573831\n",
            "epoch 261: w =2.181,loss=0.09561436\n",
            "epoch 262: w =2.181,loss=0.09549110\n",
            "epoch 263: w =2.182,loss=0.09536862\n",
            "epoch 264: w =2.182,loss=0.09524678\n",
            "epoch 265: w =2.182,loss=0.09512571\n",
            "epoch 266: w =2.183,loss=0.09500538\n",
            "epoch 267: w =2.183,loss=0.09488583\n",
            "epoch 268: w =2.183,loss=0.09476692\n",
            "epoch 269: w =2.184,loss=0.09464876\n",
            "epoch 270: w =2.184,loss=0.09453125\n",
            "epoch 271: w =2.184,loss=0.09441449\n",
            "epoch 272: w =2.185,loss=0.09429839\n",
            "epoch 273: w =2.185,loss=0.09418303\n",
            "epoch 274: w =2.185,loss=0.09406832\n",
            "epoch 275: w =2.186,loss=0.09395430\n",
            "epoch 276: w =2.186,loss=0.09384098\n",
            "epoch 277: w =2.186,loss=0.09372835\n",
            "epoch 278: w =2.187,loss=0.09361637\n",
            "epoch 279: w =2.187,loss=0.09350512\n",
            "epoch 280: w =2.187,loss=0.09339444\n",
            "epoch 281: w =2.188,loss=0.09328444\n",
            "epoch 282: w =2.188,loss=0.09317514\n",
            "epoch 283: w =2.188,loss=0.09306645\n",
            "epoch 284: w =2.189,loss=0.09295845\n",
            "epoch 285: w =2.189,loss=0.09285109\n",
            "epoch 286: w =2.189,loss=0.09274437\n",
            "epoch 287: w =2.190,loss=0.09263824\n",
            "epoch 288: w =2.190,loss=0.09253284\n",
            "epoch 289: w =2.190,loss=0.09242795\n",
            "epoch 290: w =2.191,loss=0.09232374\n",
            "epoch 291: w =2.191,loss=0.09222016\n",
            "epoch 292: w =2.191,loss=0.09211724\n",
            "epoch 293: w =2.192,loss=0.09201491\n",
            "epoch 294: w =2.192,loss=0.09191320\n",
            "epoch 295: w =2.192,loss=0.09181207\n",
            "epoch 296: w =2.193,loss=0.09171154\n",
            "epoch 297: w =2.193,loss=0.09161165\n",
            "epoch 298: w =2.193,loss=0.09151231\n",
            "epoch 299: w =2.194,loss=0.09141359\n",
            "epoch 300: w =2.194,loss=0.09131543\n",
            "epoch 301: w =2.194,loss=0.09121795\n",
            "epoch 302: w =2.195,loss=0.09112092\n",
            "epoch 303: w =2.195,loss=0.09102456\n",
            "epoch 304: w =2.195,loss=0.09092878\n",
            "epoch 305: w =2.196,loss=0.09083354\n",
            "epoch 306: w =2.196,loss=0.09073885\n",
            "epoch 307: w =2.196,loss=0.09064475\n",
            "epoch 308: w =2.197,loss=0.09055120\n",
            "epoch 309: w =2.197,loss=0.09045824\n",
            "epoch 310: w =2.197,loss=0.09036584\n",
            "epoch 311: w =2.197,loss=0.09027396\n",
            "epoch 312: w =2.198,loss=0.09018264\n",
            "epoch 313: w =2.198,loss=0.09009185\n",
            "epoch 314: w =2.198,loss=0.09000165\n",
            "epoch 315: w =2.199,loss=0.08991192\n",
            "epoch 316: w =2.199,loss=0.08982279\n",
            "epoch 317: w =2.199,loss=0.08973417\n",
            "epoch 318: w =2.200,loss=0.08964608\n",
            "epoch 319: w =2.200,loss=0.08955846\n",
            "epoch 320: w =2.200,loss=0.08947145\n",
            "epoch 321: w =2.200,loss=0.08938492\n",
            "epoch 322: w =2.201,loss=0.08929895\n",
            "epoch 323: w =2.201,loss=0.08921344\n",
            "epoch 324: w =2.201,loss=0.08912846\n",
            "epoch 325: w =2.202,loss=0.08904400\n",
            "epoch 326: w =2.202,loss=0.08896000\n",
            "epoch 327: w =2.202,loss=0.08887657\n",
            "epoch 328: w =2.203,loss=0.08879361\n",
            "epoch 329: w =2.203,loss=0.08871111\n",
            "epoch 330: w =2.203,loss=0.08862916\n",
            "epoch 331: w =2.203,loss=0.08854768\n",
            "epoch 332: w =2.204,loss=0.08846667\n",
            "epoch 333: w =2.204,loss=0.08838618\n",
            "epoch 334: w =2.204,loss=0.08830607\n",
            "epoch 335: w =2.205,loss=0.08822653\n",
            "epoch 336: w =2.205,loss=0.08814747\n",
            "epoch 337: w =2.205,loss=0.08806887\n",
            "epoch 338: w =2.205,loss=0.08799072\n",
            "epoch 339: w =2.206,loss=0.08791306\n",
            "epoch 340: w =2.206,loss=0.08783582\n",
            "epoch 341: w =2.206,loss=0.08775911\n",
            "epoch 342: w =2.207,loss=0.08768281\n",
            "epoch 343: w =2.207,loss=0.08760699\n",
            "epoch 344: w =2.207,loss=0.08753165\n",
            "epoch 345: w =2.207,loss=0.08745670\n",
            "epoch 346: w =2.208,loss=0.08738219\n",
            "epoch 347: w =2.208,loss=0.08730821\n",
            "epoch 348: w =2.208,loss=0.08723456\n",
            "epoch 349: w =2.208,loss=0.08716148\n",
            "epoch 350: w =2.209,loss=0.08708871\n",
            "epoch 351: w =2.209,loss=0.08701646\n",
            "epoch 352: w =2.209,loss=0.08694459\n",
            "epoch 353: w =2.210,loss=0.08687321\n",
            "epoch 354: w =2.210,loss=0.08680221\n",
            "epoch 355: w =2.210,loss=0.08673167\n",
            "epoch 356: w =2.210,loss=0.08666152\n",
            "epoch 357: w =2.211,loss=0.08659178\n",
            "epoch 358: w =2.211,loss=0.08652250\n",
            "epoch 359: w =2.211,loss=0.08645353\n",
            "epoch 360: w =2.211,loss=0.08638512\n",
            "epoch 361: w =2.212,loss=0.08631709\n",
            "epoch 362: w =2.212,loss=0.08624935\n",
            "epoch 363: w =2.212,loss=0.08618216\n",
            "epoch 364: w =2.213,loss=0.08611522\n",
            "epoch 365: w =2.213,loss=0.08604883\n",
            "epoch 366: w =2.213,loss=0.08598275\n",
            "epoch 367: w =2.213,loss=0.08591710\n",
            "epoch 368: w =2.214,loss=0.08585178\n",
            "epoch 369: w =2.214,loss=0.08578695\n",
            "epoch 370: w =2.214,loss=0.08572240\n",
            "epoch 371: w =2.214,loss=0.08565833\n",
            "epoch 372: w =2.215,loss=0.08559460\n",
            "epoch 373: w =2.215,loss=0.08553129\n",
            "epoch 374: w =2.215,loss=0.08546831\n",
            "epoch 375: w =2.215,loss=0.08540570\n",
            "epoch 376: w =2.216,loss=0.08534347\n",
            "epoch 377: w =2.216,loss=0.08528165\n",
            "epoch 378: w =2.216,loss=0.08522016\n",
            "epoch 379: w =2.216,loss=0.08515906\n",
            "epoch 380: w =2.217,loss=0.08509836\n",
            "epoch 381: w =2.217,loss=0.08503792\n",
            "epoch 382: w =2.217,loss=0.08497798\n",
            "epoch 383: w =2.217,loss=0.08491825\n",
            "epoch 384: w =2.218,loss=0.08485895\n",
            "epoch 385: w =2.218,loss=0.08480009\n",
            "epoch 386: w =2.218,loss=0.08474147\n",
            "epoch 387: w =2.218,loss=0.08468321\n",
            "epoch 388: w =2.219,loss=0.08462531\n",
            "epoch 389: w =2.219,loss=0.08456773\n",
            "epoch 390: w =2.219,loss=0.08451057\n",
            "epoch 391: w =2.219,loss=0.08445371\n",
            "epoch 392: w =2.220,loss=0.08439721\n",
            "epoch 393: w =2.220,loss=0.08434097\n",
            "epoch 394: w =2.220,loss=0.08428517\n",
            "epoch 395: w =2.220,loss=0.08422964\n",
            "epoch 396: w =2.221,loss=0.08417446\n",
            "epoch 397: w =2.221,loss=0.08411962\n",
            "epoch 398: w =2.221,loss=0.08406508\n",
            "epoch 399: w =2.221,loss=0.08401091\n",
            "epoch 400: w =2.221,loss=0.08395702\n",
            "epoch 401: w =2.222,loss=0.08390345\n",
            "epoch 402: w =2.222,loss=0.08385023\n",
            "epoch 403: w =2.222,loss=0.08379731\n",
            "epoch 404: w =2.222,loss=0.08374473\n",
            "epoch 405: w =2.223,loss=0.08369251\n",
            "epoch 406: w =2.223,loss=0.08364046\n",
            "epoch 407: w =2.223,loss=0.08358876\n",
            "epoch 408: w =2.223,loss=0.08353745\n",
            "epoch 409: w =2.224,loss=0.08348645\n",
            "epoch 410: w =2.224,loss=0.08343568\n",
            "epoch 411: w =2.224,loss=0.08338520\n",
            "epoch 412: w =2.224,loss=0.08333510\n",
            "epoch 413: w =2.224,loss=0.08328532\n",
            "epoch 414: w =2.225,loss=0.08323568\n",
            "epoch 415: w =2.225,loss=0.08318647\n",
            "epoch 416: w =2.225,loss=0.08313754\n",
            "epoch 417: w =2.225,loss=0.08308890\n",
            "epoch 418: w =2.226,loss=0.08304051\n",
            "epoch 419: w =2.226,loss=0.08299249\n",
            "epoch 420: w =2.226,loss=0.08294470\n",
            "epoch 421: w =2.226,loss=0.08289716\n",
            "epoch 422: w =2.226,loss=0.08284993\n",
            "epoch 423: w =2.227,loss=0.08280303\n",
            "epoch 424: w =2.227,loss=0.08275639\n",
            "epoch 425: w =2.227,loss=0.08271004\n",
            "epoch 426: w =2.227,loss=0.08266389\n",
            "epoch 427: w =2.228,loss=0.08261812\n",
            "epoch 428: w =2.228,loss=0.08257253\n",
            "epoch 429: w =2.228,loss=0.08252728\n",
            "epoch 430: w =2.228,loss=0.08248225\n",
            "epoch 431: w =2.228,loss=0.08243752\n",
            "epoch 432: w =2.229,loss=0.08239304\n",
            "epoch 433: w =2.229,loss=0.08234885\n",
            "epoch 434: w =2.229,loss=0.08230491\n",
            "epoch 435: w =2.229,loss=0.08226126\n",
            "epoch 436: w =2.230,loss=0.08221784\n",
            "epoch 437: w =2.230,loss=0.08217470\n",
            "epoch 438: w =2.230,loss=0.08213177\n",
            "epoch 439: w =2.230,loss=0.08208913\n",
            "epoch 440: w =2.230,loss=0.08204673\n",
            "epoch 441: w =2.231,loss=0.08200455\n",
            "epoch 442: w =2.231,loss=0.08196270\n",
            "epoch 443: w =2.231,loss=0.08192108\n",
            "epoch 444: w =2.231,loss=0.08187966\n",
            "epoch 445: w =2.231,loss=0.08183859\n",
            "epoch 446: w =2.232,loss=0.08179771\n",
            "epoch 447: w =2.232,loss=0.08175708\n",
            "epoch 448: w =2.232,loss=0.08171666\n",
            "epoch 449: w =2.232,loss=0.08167653\n",
            "epoch 450: w =2.232,loss=0.08163656\n",
            "epoch 451: w =2.233,loss=0.08159691\n",
            "epoch 452: w =2.233,loss=0.08155748\n",
            "epoch 453: w =2.233,loss=0.08151825\n",
            "epoch 454: w =2.233,loss=0.08147927\n",
            "epoch 455: w =2.233,loss=0.08144059\n",
            "epoch 456: w =2.234,loss=0.08140204\n",
            "epoch 457: w =2.234,loss=0.08136371\n",
            "epoch 458: w =2.234,loss=0.08132574\n",
            "epoch 459: w =2.234,loss=0.08128793\n",
            "epoch 460: w =2.234,loss=0.08125027\n",
            "epoch 461: w =2.235,loss=0.08121294\n",
            "epoch 462: w =2.235,loss=0.08117583\n",
            "epoch 463: w =2.235,loss=0.08113887\n",
            "epoch 464: w =2.235,loss=0.08110215\n",
            "epoch 465: w =2.235,loss=0.08106567\n",
            "epoch 466: w =2.236,loss=0.08102941\n",
            "epoch 467: w =2.236,loss=0.08099337\n",
            "epoch 468: w =2.236,loss=0.08095755\n",
            "epoch 469: w =2.236,loss=0.08092197\n",
            "epoch 470: w =2.236,loss=0.08088654\n",
            "epoch 471: w =2.237,loss=0.08085131\n",
            "epoch 472: w =2.237,loss=0.08081628\n",
            "epoch 473: w =2.237,loss=0.08078159\n",
            "epoch 474: w =2.237,loss=0.08074693\n",
            "epoch 475: w =2.237,loss=0.08071262\n",
            "epoch 476: w =2.237,loss=0.08067850\n",
            "epoch 477: w =2.238,loss=0.08064457\n",
            "epoch 478: w =2.238,loss=0.08061073\n",
            "epoch 479: w =2.238,loss=0.08057722\n",
            "epoch 480: w =2.238,loss=0.08054382\n",
            "epoch 481: w =2.238,loss=0.08051068\n",
            "epoch 482: w =2.239,loss=0.08047775\n",
            "epoch 483: w =2.239,loss=0.08044507\n",
            "epoch 484: w =2.239,loss=0.08041246\n",
            "epoch 485: w =2.239,loss=0.08038015\n",
            "epoch 486: w =2.239,loss=0.08034793\n",
            "epoch 487: w =2.240,loss=0.08031593\n",
            "epoch 488: w =2.240,loss=0.08028417\n",
            "epoch 489: w =2.240,loss=0.08025260\n",
            "epoch 490: w =2.240,loss=0.08022116\n",
            "epoch 491: w =2.240,loss=0.08018999\n",
            "epoch 492: w =2.240,loss=0.08015893\n",
            "epoch 493: w =2.241,loss=0.08012813\n",
            "epoch 494: w =2.241,loss=0.08009746\n",
            "epoch 495: w =2.241,loss=0.08006698\n",
            "epoch 496: w =2.241,loss=0.08003667\n",
            "epoch 497: w =2.241,loss=0.08000660\n",
            "epoch 498: w =2.241,loss=0.07997663\n",
            "epoch 499: w =2.242,loss=0.07994686\n",
            "epoch 500: w =2.242,loss=0.07991730\n",
            "prediction after training:f(5)=10.380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VIVPITo9HPqJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}